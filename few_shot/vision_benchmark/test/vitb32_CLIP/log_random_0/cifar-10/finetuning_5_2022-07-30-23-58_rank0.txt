2022-07-30 23:58:31,838:[P:4947]:Rank[0/1] => collecting env info (might take some time)
2022-07-30 23:58:37,696:[P:4947]:Rank[0/1] 
PyTorch version: 1.8.0
Is debug build: False
CUDA used to build PyTorch: 11.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.2 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.16.3

Python version: 3.9 (64-bit runtime)
Is CUDA available: True
CUDA runtime version: Could not collect
GPU models and configuration: 
GPU 0: NVIDIA RTX A6000
GPU 1: NVIDIA RTX A6000
GPU 2: NVIDIA RTX A6000
GPU 3: NVIDIA RTX A6000

Nvidia driver version: 470.74
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.2
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.22.3
[pip3] torch==1.8.0
[pip3] torchaudio==0.8.0a0+a751e1d
[pip3] torchvision==0.9.0
[conda] blas                      1.0                         mkl  
[conda] cudatoolkit               11.1.1               h6406543_8    conda-forge
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0            py39h7f8727e_0  
[conda] mkl_fft                   1.3.1            py39hd3c417c_0  
[conda] mkl_random                1.2.2            py39h51133e4_0  
[conda] numpy                     1.22.3                   pypi_0    pypi
[conda] pytorch                   1.8.0           py3.9_cuda11.1_cudnn8.0.5_0    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                0.8.0                      py39    pytorch
[conda] torchvision               0.9.0                py39_cu111    pytorch
2022-07-30 23:58:37,696:[P:4947]:Rank[0/1] Namespace(ds='resources/datasets/cifar10.yaml', model='resources/model/vitb32_CLIP.yaml', submit_predictions=False, submit_by=None, target='local', classifier='logistic', save_feature=False, no_tuning=False, l2=0.316, lr=0.001, run=1, fix_seed=0, opts=['DATASET.NUM_SAMPLES_PER_CLASS', '5', 'DATASET.RANDOM_SEED_SAMPLING', '0', 'TRAIN.TWO_LR', 'False', 'DATASET.ROOT', '/data1/xh/', 'OUTPUT_DIR', './test/vitb32_CLIP/log_random_0', 'TRAIN.INIT_HEAD_WITH_TEXT_ENCODER', 'True', 'MODEL.CLIP_FP32', 'True'], cfg='resources/model/vitb32_CLIP.yaml')
2022-07-30 23:58:37,697:[P:4947]:Rank[0/1] AMP:
  ENABLED: False
  MEMORY_FORMAT: nchw
AUG:
  COLOR_JITTER: [0.4, 0.4, 0.4, 0.1, 0.0]
  DROPBLOCK_BLOCK_SIZE: 7
  DROPBLOCK_KEEP_PROB: 1.0
  DROPBLOCK_LAYERS: [3, 4]
  GAUSSIAN_BLUR: 0.0
  GRAY_SCALE: 0.0
  MIXCUT: 0.0
  MIXCUT_AND_MIXUP: False
  MIXCUT_MINMAX: []
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 0.0
  MIXUP_SWITCH_PROB: 0.5
  RANDOM_CENTER_CROP: False
  RATIO: (0.75, 1.3333333333333333)
  SCALE: (0.08, 1.0)
  TIMM_AUG:
    USE_LOADER: False
    USE_TRANSFORM: False
BASE: ['']
CUDNN:
  BENCHMARK: True
  DETERMINISTIC: False
  ENABLED: True
DATASET:
  CENTER_CROP: True
  COCO:
    BALANCE_DATA: True
    SCALES: ['m', 'l']
  DATASET: cifar-10
  DATA_FORMAT: jpg
  IMAGE_SIZE: (224,)
  LABELMAP: 
  MERGE_TRAIN_VAL_FINAL_RUN: True
  NUM_CLASSES: 10
  NUM_SAMPLES_PER_CLASS: 5
  RANDOM_SEED_SAMPLING: 0
  ROOT: /data1/xh/
  TARGET_SIZE: -1
  TEST_SET: val
  TEST_TSV_LIST: []
  TRAIN_SET: train
  TRAIN_TSV_LIST: []
  VAL_SET: 
DATA_DIR: 
DEBUG:
  DEBUG: False
DEEPSPEED:
  
DIST_BACKEND: nccl
FINETUNE:
  BASE_LR: 0.003
  BATCH_SIZE: 512
  EVAL_EVERY: 3000
  FINETUNE: False
  FROZEN_LAYERS: []
  USE_TRAIN_AUG: False
GPUS: (0,)
INPUT:
  MEAN: [0.48145466, 0.4578275, 0.40821073]
  STD: [0.26862954, 0.26130258, 0.27577711]
KNOWLEDGE:
  AGGREGATION:
    MEHTOD: WIKI_THEN_GPT3
    NUM_GPT3_ITEMS: 1
  GPT3:
    GPT3_DICT_PATH: resources/knowledge/gpt3
    USE_GPT3: False
  WIKITIONARY:
    PRE_EXTRACTED: False
    USE_DEFINITION: False
    WIKI_DB_PATH: /home/chunyl/project/load_wiki
    WIKI_DICT_PATH: resources/knowledge/external
  WORDNET:
    USE_DEFINITION: False
    USE_HIERARCHY: False
LOSS:
  FOCAL:
    ALPHA: 1.0
    GAMMA: 0.5
    NORMALIZE: True
  LABEL_SMOOTHING: 0.0
  LOSS: softmax
MODEL:
  AUTHOR: OpenAI
  CLIP_FP32: True
  CREATION_TIME: 2021-01-05
  INIT_WEIGHTS: True
  NAME: ViT-B/32
  NUM_CLASSES: 1000
  NUM_PARAMS_IN_M: 151.2
  PRETRAINED: 
  PRETRAINED_DATA: CLIP-data
  PRETRAINED_LAYERS: ['*']
  SPEC:
    EMBED_DIM: 512
    TEXT:
      CONTEXT_LENGTH: 77
      HEADS: 8
      LAYERS: 12
      STYLE: clip
      TOKENIZER: clip
      VOCAB_SIZE: 49408
      WIDTH: 512
    VISION:
      LAYERS: 12
      MODEL: vit
      PATCH_SIZE: 32
      WIDTH: 384
MULTIPROCESSING_DISTRIBUTED: True
NAME: 
OUTPUT_DIR: ./test/vitb32_CLIP/log_random_0
PIN_MEMORY: True
PRINT_FREQ: 20
RANK: 0
SWA:
  ANNEAL_EPOCHS: 10
  ANNEAL_STRATEGY: cos
  BEGIN_EPOCH: -1
  DEVICE: cpu
  ENABLED: False
  FROZEN_BN: False
  LR_RATIO: 0.5
TEST:
  BATCH_SIZE_PER_GPU: 128
  CENTER_CROP: True
  IMAGE_SIZE: [224, 224]
  INTERPOLATION: 2
  METRIC: accuracy
  MODEL_FILE: 
  REAL_LABELS: False
  VALID_LABELS: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE_PER_GPU: 64
  BEGIN_EPOCH: 0
  CHECKPOINT: 
  CLIP_GRAD_NORM: 0.0
  DETECT_ANOMALY: False
  EMA_DECAY: 0.0
  EMULATE_ZERO_SHOT: False
  END_EPOCH: 10
  EVAL_BEGIN_EPOCH: 0
  EXTRA_FINAL_TRAIN_EPOCH: 40
  FREEZE_IMAGE_BACKBONE: False
  GAMMA1: 0.99
  GAMMA2: 0.0
  IMAGE_SIZE: [224, 224]
  INIT_HEAD_WITH_LOGIT_SCALE: False
  INIT_HEAD_WITH_TEXT_ENCODER: True
  LARC: False
  LOADER: blobfuse
  LR: 0.001
  LR_SCHEDULER:
    METHOD: WarmupCosine
    WARMUP_EPOCH: 5
  MERGE_ENCODER_AND_HEAD_PROJ: False
  MOMENTUM: 0.9
  NESTEROV: False
  NORMALIZE_VISUAL_FEATURE: False
  NUM_SAMPLES_CLASS: average
  OPTIMIZER: sgd
  OPTIMIZER_ARGS:
    
  SAMPLER: default
  SAVE_ALL_MODELS: False
  SCHEDULE: []
  SEARCH_RESULT_ON_LAST_EPOCH: False
  SEARCH_WD_LOG_LOWER: -6
  SEARCH_WD_LOG_UPPER: 6
  SHUFFLE: True
  TWO_LR: False
  WD: 0.0
  WITHOUT_WD_LIST: []
USE_DEEPSPEED: False
VERBOSE: True
WORKERS: 4
2022-07-30 23:58:37,698:[P:4947]:Rank[0/1] => saving logging info into: test/vitb32_CLIP/log_random_0/cifar-10
2022-07-30 23:58:37,698:[P:4947]:Rank[0/1] cifar-10 is a dataset.
2022-07-30 23:58:37,698:[P:4947]:Rank[0/1] Do center crop
2022-07-30 23:58:37,712:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/labels.txt exists. Skip downloading.
2022-07-30 23:58:37,712:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/test.txt exists. Skip downloading.
2022-07-30 23:58:37,712:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/val.zip exists. Skip downloading.
2022-07-30 23:58:37,755:[P:4947]:Rank[0/1] Test size is 10000.
2022-07-30 23:58:37,755:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/labels.txt exists. Skip downloading.
2022-07-30 23:58:37,755:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/train.zip exists. Skip downloading.
2022-07-30 23:58:37,755:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/train.txt exists. Skip downloading.
2022-07-30 23:58:38,091:[P:4947]:Rank[0/1] /data1/xh/classification/cifar_10_20211007/labels.txt exists. Skip downloading.
2022-07-30 23:58:38,111:[P:4947]:Rank[0/1] Quick fetch label starts.
2022-07-30 23:58:38,111:[P:4947]:Rank[0/1] Quick fetch label finished.
2022-07-30 23:58:38,111:[P:4947]:Rank[0/1] Val split from Train set: Train size is 40.0, and validation size is 10.0.
2022-07-30 23:58:38,120:[P:4947]:Rank[0/1] Finetuning with full model. This may take several minutes to hours depending on the size of your data.
2022-07-30 23:58:38,120:[P:4947]:Rank[0/1] => The final classifier is on training ...
2022-07-30 23:58:38,120:[P:4947]:Rank[0/1] Hyperparameters: learning_rate = 0.001, l2_lambda = 0.316
2022-07-30 23:58:38,120:[P:4947]:Rank[0/1] Using the full trainval set to train final model. len(dataset)=50
