OUTPUT_DIR: 'OUTPUT/'
WORKERS: 6
PRINT_FREQ: 2000
AMP:
  ENABLED: true

MODEL:
  NAME: clip_openai
  SPEC:
    EMBED_DIM: 512
    VISION:
      MODEL: vit
      PATCH_SIZE: 16
      WIDTH: 384
      LAYERS: 12
    TEXT:
      TOKENIZER: clip
      STYLE: clip
      CONTEXT_LENGTH: 77
      VOCAB_SIZE: 49408
      WIDTH: 512
      HEADS: 8
      LAYERS: 12
AUG:
  RANDOM_CENTER_CROP: True
LOSS:
  LOSS: clip_contrastive
CUDNN:
  BENCHMARK: true
  DETERMINISTIC: false
  ENABLED: true
DATASET:
  DATASET: 'image_text_pairs'
  DATA_FORMAT: 'tsv'
  ROOT: 'DATASET/yfcc100m/'
  TEST_SET: 'val'
  TRAIN_SET: 'train'
TEST:
  BATCH_SIZE_PER_GPU: 32
  IMAGE_SIZE: [224, 224]
  MODEL_FILE: ''
TRAIN:
  BATCH_SIZE_PER_GPU: 256
  LR: 0.0001
  IMAGE_SIZE: [224, 224]
  BEGIN_EPOCH: 0
  END_EPOCH: 300
  LR_SCHEDULER:
    METHOD: 'timm'
    ARGS:
      sched: 'cosine'
      warmup_epochs: 5
      warmup_lr: 0.000001
      min_lr: 0.00001
      cooldown_epochs: 10
      decay_rate: 0.1
  OPTIMIZER: adamW
  WD: 0.05
  WITHOUT_WD_LIST: ['bn', 'bias', 'ln']
  MOMENTUM: 0.9
  NESTEROV: true
  SHUFFLE: true
  SAMPLER: 'chunk'
DEBUG:
  DEBUG: false
